#!/usr/bin/env python3
"""
Science Live Orchestrator
This script uses the nanopub-content-generator as an installed Python package to generate outputs from one or more nanopublications.
It handles async/await for the nanopub-content-generator package.
"""

import os
import json
import time
import asyncio
from datetime import datetime
from pathlib import Path

def setup_directories():
    """Create necessary directories for output"""
    directories = ["results", "logs", "config", "results/content"]
    for directory in directories:
        Path(directory).mkdir(exist_ok=True)
    print("‚úÖ Output directories created")

def create_content_configs(nanopub_urls, content_types, ai_model, user_instructions, batch_id, batch_description):
    """Create configuration objects for the content generator package"""
    
    configs = []
    
    for content_type in content_types:
        config = {
            "nanopub_uris": nanopub_urls,
            "template": content_type,
            "model": ai_model,
            "description": f"{batch_description or 'Science Live content generation'} - {content_type}",
            "user_instructions": user_instructions or f"Create engaging {content_type.replace('_', ' ')} content that maintains scientific accuracy while being accessible to the target audience.",
            "notes": f"Generated by Science Live GUI for {content_type} content type. Batch: {batch_id}",
            "batch_metadata": {
                "batch_id": batch_id,
                "content_type": content_type,
                "ai_model": ai_model,
                "created_at": datetime.now().isoformat(),
                "source": "science-live-gui"
            }
        }
        
        configs.append(config)
        
        # Also save config file for debugging/reference
        config_filename = f"config/{content_type}_{batch_id}.json"
        with open(config_filename, 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
        print(f"‚úÖ Created config: {config_filename}")
    
    return configs

async def run_content_generation_async(configs):
    """Run content generation using the installed package - ASYNC VERSION"""
    try:
        # Import the content generator package
        from nanopub_content_generator import NanopubContentGenerator
        print("‚úÖ Successfully imported nanopub_content_generator package")
        
    except ImportError as e:
        print(f"‚ùå Failed to import nanopub_content_generator package: {e}")
        print("Make sure it's installed: pip install git+https://github.com/ScienceLiveHub/nanopub-content-generator.git")
        return []
    
    # Initialize the content generator
    try:
        generator = NanopubContentGenerator()
        print("‚úÖ Initialized content generator")
    except Exception as e:
        print(f"‚ùå Failed to initialize content generator: {e}")
        return []
    
    generated_files = []
    
    # Process each configuration
    for i, config in enumerate(configs, 1):
        content_type = config['batch_metadata']['content_type']
        batch_id = config['batch_metadata']['batch_id']
        
        print(f"\nüéØ Processing {i}/{len(configs)}: {content_type}")
        
        try:
            # FIXED: Properly await the async method
            result = await generator.run_pipeline(
                nanopub_uris=config['nanopub_uris'],
                template_name=config['template'],
                ollama_model=config['model'],
                user_instructions=config['user_instructions'],
                description=config['description']
            )
            
            if "error" in result:
                print(f"‚ùå Content generation failed for {content_type}: {result['error']}")
                error_file = create_error_file(content_type, batch_id, result['error'])
                if error_file:
                    generated_files.append(error_file)
            else:
                print(f"‚úÖ Content generation successful for {content_type}")
                
                # Save the generated content
                content_file = save_generated_content(
                    content=result['generated_content'],
                    content_type=content_type,
                    batch_id=batch_id,
                    citations=result.get('source_citations', ''),
                    metadata=result.get('metadata', {})
                )
                
                if content_file:
                    generated_files.append(content_file)
                    print(f"üìÑ Saved: {content_file}")
        
        except Exception as e:
            print(f"‚ùå Error processing {content_type}: {e}")
            import traceback
            traceback.print_exc()
            error_file = create_error_file(content_type, batch_id, str(e))
            if error_file:
                generated_files.append(error_file)
    
    return generated_files

def run_content_generation(configs):
    """Synchronous wrapper for async content generation"""
    return asyncio.run(run_content_generation_async(configs))

def save_generated_content(content, content_type, batch_id, citations="", metadata=None):
    """Save generated content to a file"""
    filename = f"results/content/{content_type}_{batch_id}.txt"
    
    try:
        os.makedirs(os.path.dirname(filename), exist_ok=True)
        
        with open(filename, 'w', encoding='utf-8') as f:
            # Write header
            f.write(f"# {content_type.upper().replace('_', ' ')} CONTENT\n")
            f.write(f"Generated by Science Live Content Generator\n")
            f.write(f"Batch ID: {batch_id}\n")
            f.write(f"Content Type: {content_type}\n")
            f.write(f"Generated: {datetime.now().isoformat()}\n\n")
            f.write("=" * 60 + "\n\n")
            
            # Write main content
            f.write(content)
            
            # Write citations if available
            if citations:
                f.write(f"\n\n" + "=" * 60)
                f.write(f"\nSOURCE CITATIONS\n")
                f.write("=" * 60 + "\n\n")
                f.write(citations)
            
            # Write metadata if available
            if metadata:
                f.write(f"\n\n" + "=" * 60)
                f.write(f"\nMETADATA\n")
                f.write("=" * 60 + "\n\n")
                for key, value in metadata.items():
                    f.write(f"{key}: {value}\n")
            
            f.write(f"\n\n" + "=" * 60)
            f.write(f"\nGenerated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        return filename
        
    except Exception as e:
        print(f"‚ùå Error saving content for {content_type}: {e}")
        return None

def create_error_file(content_type, batch_id, error_message):
    """Create an error file when content generation fails"""
    error_file = f"results/content/{content_type}_{batch_id}_ERROR.txt"
    
    try:
        os.makedirs(os.path.dirname(error_file), exist_ok=True)
        
        with open(error_file, 'w', encoding='utf-8') as f:
            f.write(f"# ERROR: {content_type.upper().replace('_', ' ')}\n\n")
            f.write(f"Content generation failed for {content_type}\n\n")
            f.write(f"Error Details:\n")
            f.write(f"{error_message}\n\n")
            f.write(f"Batch ID: {batch_id}\n")
            f.write(f"Content Type: {content_type}\n")
            f.write(f"Generated: {datetime.now().isoformat()}\n\n")
            f.write("TROUBLESHOOTING:\n")
            f.write("- Check that nanopub URLs are accessible\n")
            f.write("- Verify AI model is available in Ollama\n")
            f.write("- Check network connectivity\n")
            f.write("- Review template configuration\n")
        
        return error_file
        
    except Exception as e:
        print(f"‚ùå Could not create error file: {e}")
        return None

async def async_main():
    """Async main function using package-based approach"""
    print("=== SCIENCE LIVE PACKAGE-BASED ORCHESTRATOR (FIXED) ===")
    print("üéØ Clean architecture using nanopub-content-generator as Python package")
    print("üîß FIXED: Proper async/await handling")
    start_time = time.time()
    
    # Get environment variables
    nanopub_urls_str = os.getenv('NANOPUB_URLS', '')
    batch_id = os.getenv('BATCH_ID', f'batch_{int(time.time())}')
    content_types_str = os.getenv('CONTENT_TYPES', 'linkedin_post')
    ai_model = os.getenv('AI_MODEL', 'llama3:8b')
    user_instructions = os.getenv('USER_INSTRUCTIONS', '')
    batch_description = os.getenv('BATCH_DESCRIPTION', '')
    enable_content_generation = os.getenv('ENABLE_CONTENT_GENERATION', 'true').lower() == 'true'
    
    if not nanopub_urls_str:
        print("‚ùå ERROR: No nanopublication URLs provided")
        print("Usage: NANOPUB_URLS='url1,url2' python scripts/orchestrate_processing.py")
        return
    
    nanopub_urls = [url.strip() for url in nanopub_urls_str.split(',') if url.strip()]
    content_types = [ct.strip() for ct in content_types_str.split(',') if ct.strip()]
    
    print(f"üìä Processing {len(nanopub_urls)} nanopublications")
    print(f"üìù Selected nanopublications:")
    for i, url in enumerate(nanopub_urls, 1):
        print(f"   {i}. {url}")
    print(f"üéØ Content types: {', '.join(content_types)}")
    print(f"ü§ñ AI Model: {ai_model}")
    print(f"üÜî Batch ID: {batch_id}")
    print(f"üé® Content generation: {'ENABLED' if enable_content_generation else 'DISABLED'}")
    print(f"üì¶ Method: Python package (nanopub-content-generator)")
    
    setup_directories()
    
    generated_files = []
    
    if enable_content_generation:
        print("\nüöÄ Starting package-based content generation...")
        
        # Create configurations
        configs = create_content_configs(
            nanopub_urls, content_types, ai_model, user_instructions, batch_id, batch_description
        )
        
        # Run content generation using the package (ASYNC)
        generated_files = await run_content_generation_async(configs)
    else:
        print("‚ÑπÔ∏è  Content generation disabled")
    
    # Create results summary
    total_time = time.time() - start_time
    
    summary = {
        'batch_id': batch_id,
        'processing_method': 'python_package_async',
        'package_name': 'nanopub-content-generator',
        'total_nanopubs': len(nanopub_urls),
        'selected_nanopub_urls': nanopub_urls,
        'content_types_requested': content_types,
        'content_generated': len(generated_files),
        'processing_time': total_time,
        'ai_model': ai_model,
        'user_instructions': user_instructions,
        'batch_description': batch_description,
        'generated_files': generated_files,
        'content_generation_enabled': enable_content_generation,
        'successful_templates': len([f for f in generated_files if 'ERROR' not in f]),
        'failed_templates': len([f for f in generated_files if 'ERROR' in f]),
        'timestamp': datetime.now().isoformat(),
        'architecture': 'clean_package_based_async_fixed'
    }
    
    # Save results
    with open('results/batch_results.json', 'w', encoding='utf-8') as f:
        json.dump(summary, f, indent=2, ensure_ascii=False)
    
    # Create processing summary
    success_count = len([f for f in generated_files if 'ERROR' not in f])
    error_count = len([f for f in generated_files if 'ERROR' in f])
    
    report = f"""=== SCIENCE LIVE PACKAGE-BASED ORCHESTRATION RESULTS (FIXED) ===
Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
Batch ID: {batch_id}

=== CLEAN ARCHITECTURE SUMMARY ===
üì¶ Package: nanopub-content-generator (installed Python package)
üèóÔ∏è  Architecture: Clean separation with package-based integration
üîß Fix Applied: Proper async/await handling for run_pipeline()
üìä Nanopublications: {len(nanopub_urls)}
üéØ Content Types: {', '.join(content_types)}
ü§ñ AI Model: {ai_model}
‚è±Ô∏è  Processing Time: {total_time:.2f} seconds
‚úÖ Success Rate: {success_count}/{len(content_types)} content types
‚ùå Failed: {error_count}/{len(content_types)} content types

=== GENERATED CONTENT ===
{chr(10).join(f"üìÑ {os.path.basename(f)}" for f in generated_files) if generated_files else "No content files generated"}

=== CONFIGURATION ===
üìù User Instructions: {user_instructions or 'Default high-quality standards'}
üìã Batch Description: {batch_description or 'Science Live package-based generation'}

=== CLEAN ARCHITECTURE BENEFITS ===
‚úÖ Package-Based Integration: Clean import and function calls
‚úÖ No Repository Cloning: Direct Python package installation
‚úÖ Better Dependency Management: pip handles everything
‚úÖ Faster Execution: No git operations during runtime
‚úÖ Version Control: Specific package versions can be pinned
‚úÖ Standard Python Practices: Uses established packaging conventions
‚úÖ Proper Async Handling: Fixed coroutine execution

=== PACKAGE DETAILS ===
Installation: pip install git+https://github.com/ScienceLiveHub/nanopub-content-generator.git
Import: from nanopub_content_generator import NanopubContentGenerator
Usage: await generator.run_pipeline(...)  # Note: ASYNC
Version Management: Can pin to specific tags/commits

Generated files: {len(generated_files)}
Architecture status: {'SUCCESS' if success_count > 0 else 'NEEDS_ATTENTION'}
Package integration: {'WORKING' if success_count > 0 else 'CHECK_INSTALLATION'}
"""
    
    with open('logs/processing_summary.txt', 'w', encoding='utf-8') as f:
        f.write(report)
    
    print(report)
    
    if success_count > 0:
        print("=== ‚úÖ PACKAGE-BASED ORCHESTRATION SUCCESSFUL ===")
        print(f"Successfully generated {success_count} content types using Python package")
        print("üèóÔ∏è  Clean architecture: GUI repository + Python package integration")
        print("üîß Fix applied: Proper async/await handling")
        
        # Show content previews
        for file_path in [f for f in generated_files if 'ERROR' not in f][:2]:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                    print(f"\nüìÑ {os.path.basename(file_path)} ({len(content)} chars)")
                    print("=" * 50)
                    # Show meaningful preview (skip headers)
                    lines = content.split('\n')
                    content_lines = []
                    skip_header = True
                    for line in lines:
                        if skip_header and line.strip() and not line.startswith('=') and not line.startswith('#'):
                            skip_header = False
                        if not skip_header and line.strip():
                            content_lines.append(line)
                            if len(content_lines) >= 3:
                                break
                    preview = '\n'.join(content_lines)
                    print(preview[:200] + "..." if len(preview) > 200 else preview)
            except Exception as e:
                print(f"‚ö†Ô∏è  Could not preview {file_path}: {e}")
    else:
        print("=== ‚ùå PACKAGE-BASED ORCHESTRATION FAILED ===")
        print("No content was successfully generated")
        print("Check that:")
        print("- nanopub-content-generator package is installed")
        print("- Ollama is running with the required AI model")
        print("- Nanopublication URLs are valid and accessible")
        print("- Package dependencies are satisfied")
        print("\nInstallation command:")
        print("pip install git+https://github.com/ScienceLiveHub/nanopub-content-generator.git")

def main():
    """Main synchronous entry point"""
    try:
        asyncio.run(async_main())
    except KeyboardInterrupt:
        print("\nüõë Process interrupted by user")
    except Exception as e:
        print(f"\n‚ùå Error: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
