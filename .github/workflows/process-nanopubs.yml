# .github/workflows/process-nanopubs.yml
name: Process Nanopublications

# Configuration - Change these values to control behavior
env:
  COMMIT_RESULTS_TO_REPO: 'true'  # Set to 'true' to commit results, 'false' to only create artifacts

on:
  repository_dispatch:
    types: [process-nanopubs-direct]
  workflow_dispatch:
    inputs:
      nanopub_urls:
        description: 'Comma-separated nanopub URLs'
        required: true
        type: string
      batch_id:
        description: 'Batch ID for this processing run'
        required: false
        type: string

jobs:
  process-nanopubs:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    # Set a dynamic name for the job that includes the batch ID
    name: ${{ github.event_name == 'repository_dispatch' && format('Process Batch {0}', github.event.client_payload.batch_id) || format('Process Batch {0}', github.event.inputs.batch_id) }}
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'
    
    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        if [ -f requirements.txt ]; then
          pip install -r requirements.txt
        else
          # Fallback to minimal dependencies if requirements.txt not found
          pip install requests rdflib pandas numpy
        fi
    
    - name: Extract processing parameters
      id: params
      run: |
        if [ "${{ github.event_name }}" = "repository_dispatch" ]; then
          echo "nanopub_urls=${{ github.event.client_payload.nanopub_urls_string }}" >> $GITHUB_OUTPUT
          echo "batch_id=${{ github.event.client_payload.batch_id }}" >> $GITHUB_OUTPUT
          echo "nanopub_count=${{ github.event.client_payload.nanopub_count }}" >> $GITHUB_OUTPUT
          echo "source=${{ github.event.client_payload.source }}" >> $GITHUB_OUTPUT
        else
          echo "nanopub_urls=${{ github.event.inputs.nanopub_urls }}" >> $GITHUB_OUTPUT
          echo "batch_id=${{ github.event.inputs.batch_id }}" >> $GITHUB_OUTPUT
          echo "nanopub_count=$(echo '${{ github.event.inputs.nanopub_urls }}' | tr ',' '\n' | wc -l)" >> $GITHUB_OUTPUT
          echo "source=manual" >> $GITHUB_OUTPUT
        fi
    
    - name: Display processing info
      run: |
        echo "🚀 Starting nanopub processing"
        echo "📊 Batch ID: ${{ steps.params.outputs.batch_id }}"
        echo "🔢 Count: ${{ steps.params.outputs.nanopub_count }} nanopubs"
        echo "📋 Source: ${{ steps.params.outputs.source }}"
        echo "⏰ Started: $(date -u)"
        echo "🎯 Workflow Run: ${{ github.run_id }}"
        echo "🔗 Run URL: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
    
    - name: Run nanopub processing
      env:
        NANOPUB_URLS: ${{ steps.params.outputs.nanopub_urls }}
        NANOPUB_COUNT: ${{ steps.params.outputs.nanopub_count }}
        BATCH_ID: ${{ steps.params.outputs.batch_id }}
        PROCESSING_SOURCE: ${{ steps.params.outputs.source }}
      run: |
        echo "🔬 Executing nanopub processor..."
        cd scripts
        python process_nanopubs.py
        echo "📁 Checking generated files..."
        ls -la ../results/ 2>/dev/null || echo "No results directory found"
        ls -la ../logs/ 2>/dev/null || echo "No logs directory found"
    
    - name: Ensure directories exist for artifacts
      run: |
        echo "📁 Current directory structure before ensuring directories:"
        find . -name "results" -o -name "logs" -type d 2>/dev/null || echo "No results/logs directories found"
        
        mkdir -p results logs
        echo "📁 Created base directories"
        
        # List what files exist
        echo "📄 Files in results directory:"
        find results -type f 2>/dev/null || echo "No files in results directory"
        
        echo "📄 Files in logs directory:"
        find logs -type f 2>/dev/null || echo "No files in logs directory"
        
        # Create a basic summary file if processing failed
        if [ ! -f "logs/processing_summary.txt" ]; then
          echo "⚠️ No processing summary found - creating error file"
          echo "Processing may have failed - no summary file generated at $(date -u)" > logs/error_summary.txt
        fi
        
        if [ ! -f "results/batch_results.json" ]; then
          echo "⚠️ No batch results found - creating error file"
          echo '{"error": "No batch results generated", "timestamp": "'$(date -u +%Y-%m-%dT%H:%M:%SZ)'", "batch_id": "${{ steps.params.outputs.batch_id }}"}' > results/error_results.json
        fi
        
        echo "📄 Final file check before artifact upload:"
        find results logs -type f 2>/dev/null || echo "Still no files found"
    
    - name: Upload processing results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: nanopub-processing-results-${{ steps.params.outputs.batch_id }}
        path: |
          results/**/*
          logs/**/*
        retention-days: 30
        if-no-files-found: warn
    
    - name: Create results summary
      if: always()
      run: |
        echo "## 📊 Nanopub Processing Results" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "**Batch ID:** \`${{ steps.params.outputs.batch_id }}\`" >> $GITHUB_STEP_SUMMARY
        echo "**Nanopubs Processed:** ${{ steps.params.outputs.nanopub_count }}" >> $GITHUB_STEP_SUMMARY
        echo "**Processing Time:** $(date -d @$SECONDS -u +%H:%M:%S)" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        if [ -f "logs/processing_summary.txt" ]; then
          echo "### 📋 Processing Summary" >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          head -50 logs/processing_summary.txt >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
        fi
        
        if [ -f "results/batch_results.json" ]; then
          echo "### 📈 Quick Stats" >> $GITHUB_STEP_SUMMARY
          PROCESSED=$(jq -r '.processed' results/batch_results.json)
          FAILED=$(jq -r '.failed' results/batch_results.json)
          TOTAL_TIME=$(jq -r '.processing_time_seconds' results/batch_results.json)
          echo "- ✅ Successfully processed: $PROCESSED" >> $GITHUB_STEP_SUMMARY
          echo "- ❌ Failed: $FAILED" >> $GITHUB_STEP_SUMMARY
          echo "- ⏱️ Total time: ${TOTAL_TIME}s" >> $GITHUB_STEP_SUMMARY
        fi
        
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "📥 **Download Results:** Check the artifacts section above" >> $GITHUB_STEP_SUMMARY
    
    - name: Debug commit conditions
      if: always()
      run: |
        echo "🔍 Checking commit conditions:"
        echo "- Job status: ${{ job.status }}"
        echo "- COMMIT_RESULTS_TO_REPO: '${{ env.COMMIT_RESULTS_TO_REPO }}'"
        echo "- Should commit: ${{ env.COMMIT_RESULTS_TO_REPO == 'true' }}"
    
    - name: Commit results to repository (optional)
      if: env.COMMIT_RESULTS_TO_REPO == 'true'
      run: |
        echo "🔄 Committing results to repository..."
        echo "📊 Commit condition met - commit_results: ${{ github.event.client_payload.commit_results }}"
        
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Actions - Nanopub Processor"
        
        # Create or switch to results branch
        git fetch origin results 2>/dev/null || echo "Results branch doesn't exist yet"
        git checkout -b results 2>/dev/null || git checkout results
        
        # Merge any changes from main if needed
        git merge origin/main --no-edit --allow-unrelated-histories 2>/dev/null || echo "No merge needed"
        
        # Create results directory structure
        mkdir -p processing-results/${{ steps.params.outputs.batch_id }}
        
        # Copy results to permanent location
        if [ -d "results" ]; then
          cp -r results/* processing-results/${{ steps.params.outputs.batch_id }}/
          echo "✅ Copied results files"
        fi
        
        if [ -d "logs" ]; then
          cp -r logs/* processing-results/${{ steps.params.outputs.batch_id }}/
          echo "✅ Copied log files"
        fi
        
        # Create an index file for this batch
        cat > processing-results/${{ steps.params.outputs.batch_id }}/README.md << EOF
        # Nanopub Processing Results - ${{ steps.params.outputs.batch_id }}
        
        **Processed:** $(date -u)
        **Nanopubs:** ${{ steps.params.outputs.nanopub_count }}
        **Source:** ${{ steps.params.outputs.source }}
        **Workflow Run:** [${{ github.run_id }}](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})
        
        ## Files Generated
        - \`batch_results.json\` - Main processing results
        - \`combined_analysis.json\` - Cross-nanopub analysis
        - \`processing_summary.txt\` - Human-readable summary
        - \`individual/\` - Individual nanopub analyses
        - \`web/\` - Web display data
        
        ## Processed URLs
        ${{ steps.params.outputs.nanopub_urls }}
        EOF
        
        # Add and commit files
        git add processing-results/
        
        if ! git diff --cached --quiet; then
          git commit -m "Add processing results for batch ${{ steps.params.outputs.batch_id }}

          - Processed ${{ steps.params.outputs.nanopub_count }} nanopublications
          - Source: ${{ steps.params.outputs.source }}
          - Workflow: ${{ github.run_id }}
          - Timestamp: $(date -u)"
          
          # Push to results branch
          git push origin results
          echo "✅ Results committed and pushed to results branch"
          echo "🔗 View results: ${{ github.server_url }}/${{ github.repository }}/tree/results/processing-results/${{ steps.params.outputs.batch_id }}"
        else
          echo "ℹ️ No new results to commit"
        fi
